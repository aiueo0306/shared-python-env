import re
from datetime import datetime, timezone
from urllib.parse import urljoin

def _get_first_text_in_parent(parent_locator, selector, start_index=0):
    """
    è¦ªãƒ­ã‚±ãƒ¼ã‚¿å†…ã® selector ã«ä¸€è‡´ã™ã‚‹è¦ç´ ã‚’ start_index ã‹ã‚‰é †ã«èª¿ã¹ã€
    æœ€åˆã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ããŸè¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ï¼ˆè¦ªç¯„å›²å¤–ã«ã¯å‡ºãªã„ï¼‰
    â€» hidden å¯¾å¿œã®ãŸã‚ inner_text() ã§ã¯ãªã text_content() ã‚’ä½¿ç”¨
    """
    try:
        elements = parent_locator.locator(selector)
        count = elements.count()
    except Exception:
        return ""
    for idx in range(start_index, count):
        try:
            txt = (elements.nth(idx).text_content() or "").strip()
            if txt:
                return txt
        except Exception:
            continue
    return ""

def _get_first_attr_in_parent(parent_locator, selector, attr, start_index=0):
    """
    è¦ªãƒ­ã‚±ãƒ¼ã‚¿å†…ã® selector ã«ä¸€è‡´ã™ã‚‹è¦ç´ ã‚’ start_index ã‹ã‚‰é †ã«èª¿ã¹ã€
    æœ€åˆã« attr ã‚’å–å¾—ã§ããŸè¦ç´ ã®å€¤ã‚’è¿”ã™ï¼ˆè¦ªç¯„å›²å¤–ã«ã¯å‡ºãªã„ï¼‰
    selector ãŒç©º/None ã®å ´åˆã¯è¦ªè‡ªèº«ã‹ã‚‰ attr ã‚’å–å¾—ã™ã‚‹
    """
    if selector:
        try:
            elements = parent_locator.locator(selector)
            count = elements.count()
        except Exception:
            return None
        for idx in range(start_index, count):
            try:
                val = elements.nth(idx).get_attribute(attr)
                if val:
                    return val
            except Exception:
                continue
        return None
    else:
        # è¦ªè‡ªèº«ãŒ <a> ç­‰ã§ href ã‚’æŒã¤ã‚±ãƒ¼ã‚¹
        try:
            val = parent_locator.get_attribute(attr)
            return val
        except Exception:
            return None

def extract_items(
    page,
    SELECTOR_DATE,
    SELECTOR_TITLE,
    title_selector,
    title_index,
    href_selector,
    href_index,
    base_url,
    date_selector,
    date_index,
    date_format,  # äº’æ›ã®ãŸã‚æ®‹ã™ï¼ˆæœªä½¿ç”¨ï¼‰
    date_regex,
    max_items=10
):
    # --- ãƒšãƒ¼ã‚¸å®‰å®šåŒ– & å¯è¦–ã‚’è¦æ±‚ã—ãªã„å¾…æ©Ÿï¼ˆDOMã«ã‚¢ã‚¿ãƒƒãƒã•ã‚Œã‚Œã°OKï¼‰
    page.wait_for_load_state("domcontentloaded")
    page.wait_for_load_state("networkidle")
    page.wait_for_selector(SELECTOR_TITLE, state="attached", timeout=30000)

    blocks1 = page.locator(SELECTOR_TITLE)
    count_titles = blocks1.count()

    print(f"ğŸ“¦ ç™ºè¦‹ã—ãŸè¨˜äº‹æ•°(ã‚¿ã‚¤ãƒˆãƒ«å´): {count_titles}")
    items = []

    # æ—¥ä»˜ã‚»ãƒ¬ã‚¯ã‚¿ã¯å­˜åœ¨ã—ãªã„/åˆ¥è¡Œæ•°ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ç‹¬ç«‹ã—ã¦æ‰±ã†
    blocks2 = page.locator(SELECTOR_DATE) if SELECTOR_DATE else None
    count_dates = blocks2.count() if blocks2 else 0
    print(f"ğŸ—“ å–å¾—å¯èƒ½ãªæ—¥ä»˜ãƒ–ãƒ­ãƒƒã‚¯æ•°: {count_dates}")

    row_count = min(count_titles, max_items)

    for i in range(row_count):
        try:
            block1 = blocks1.nth(i)
            block2 = blocks2.nth(i) if blocks2 and i < count_dates else None

            # --- ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆhiddenå¯¾ç­–: text_content()ï¼‰
            if title_selector:
                title = _get_first_text_in_parent(block1, title_selector, title_index)
            else:
                try:
                    title = (block1.text_content() or "").strip()
                except Exception:
                    title = ""
            if not title and title_selector:
                # aè¦ç´ ã®titleå±æ€§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                try:
                    maybe_title = block1.locator(title_selector).nth(title_index).get_attribute("title")
                    if maybe_title:
                        title = maybe_title.strip()
                except Exception:
                    pass
            print(title)

            # --- URL
            href = _get_first_attr_in_parent(block1, href_selector, "href", href_index)
            full_link = urljoin(base_url, href) if href else base_url
            print(full_link)

            # --- æ—¥ä»˜ãƒ†ã‚­ã‚¹ãƒˆï¼ˆtitleåˆ—ã¨dateåˆ—ã®è¡Œã‚ºãƒ¬ã«è€ãˆã‚‹ï¼‰
            date_text = ""
            target_for_date = block2 if block2 else block1  # ç„¡ã‘ã‚Œã°åŒã˜è¡Œã®ã‚¿ã‚¤ãƒˆãƒ«å´ã‹ã‚‰ã‚‚æ¢ã™
            if date_selector:
                date_text = _get_first_text_in_parent(target_for_date, date_selector, date_index)
            else:
                try:
                    date_text = (target_for_date.text_content() or "").strip()
                except Exception as e:
                    print(f"âš  ç›´æ¥æ—¥ä»˜å–å¾—ã«å¤±æ•—: {e}")
                    date_text = ""
            print(date_text)

            # --- æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹ï¼ˆyyyy, mm, dd ã®3ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æƒ³å®šã—ãŸ regexï¼‰
            pub_date = None
            try:
                match = re.search(date_regex, date_text)
                if match:
                    year_str, month_str, day_str = match.groups()
                    year = int(year_str)
                    if year < 100:
                        year += 2000  # 2æ¡è¥¿æš¦ã¯2000å¹´ä»¥é™ã¨ä»®å®š
                    pub_date = datetime(year, int(month_str), int(day_str), tzinfo=timezone.utc)
                else:
                    print("âš  æ—¥ä»˜ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
            except Exception as e:
                print(f"âš  æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—: {e}")
                pub_date = None

            print(pub_date)

            # --- å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
            if not title or not href:
                print(f"âš  å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ¬ è½ã—ãŸãŸã‚ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ{i+1}è¡Œç›®ï¼‰: title='{title}', href='{href}'")
                continue

            items.append({
                "title": title,
                "link": full_link,
                "description": title,
                "pub_date": pub_date
            })

        except Exception as e:
            print(f"âš  è¡Œ{i+1}ã®è§£æã«å¤±æ•—: {e}")
            continue

    return items
